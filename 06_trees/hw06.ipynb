{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f11065ac",
   "metadata": {},
   "source": [
    "# HW06 - Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382dbc27",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "In this homework, we continue using the fuel efficiency dataset.\n",
    "Download it from <a href='https://raw.githubusercontent.com/alexeygrigorev/datasets/master/car_fuel_efficiency.csv'>here</a>.\n",
    "\n",
    "You can do it with wget:\n",
    "\n",
    "```bash\n",
    "wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/car_fuel_efficiency.csv\n",
    "```\n",
    "\n",
    "The goal of this homework is to create a regression model for predicting the car fuel efficiency (column `'fuel_efficiency_mpg'`).\n",
    "\n",
    "\n",
    "\n",
    "### Preparing the dataset \n",
    "\n",
    "Preparation:\n",
    "\n",
    "* Fill missing values with zeros.\n",
    "* Do train/validation/test split with 60%/20%/20% distribution. \n",
    "* Use the `train_test_split` function and set the `random_state` parameter to 1.\n",
    "* Use `DictVectorizer(sparse=True)` to turn the dataframes into matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d2702f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import export_text\n",
    "from IPython.display import display\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dbaf318",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/car_fuel_efficiency.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44b4bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The target variable is 'fuel_efficiency_mpg'.\n",
    "target = \"fuel_efficiency_mpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6ccbeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "string_columns = list(df.dtypes[df.dtypes == \"object\"].index)\n",
    "\n",
    "for col in string_columns:\n",
    "    df[col] = df[col].str.lower().str.replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "875aa846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine_displacement</th>\n",
       "      <th>num_cylinders</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>vehicle_weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>drivetrain</th>\n",
       "      <th>num_doors</th>\n",
       "      <th>fuel_efficiency_mpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170</td>\n",
       "      <td>3.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>3413.433759</td>\n",
       "      <td>17.7</td>\n",
       "      <td>2003</td>\n",
       "      <td>europe</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>all-wheel_drive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.231729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130</td>\n",
       "      <td>5.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>3149.664934</td>\n",
       "      <td>17.8</td>\n",
       "      <td>2007</td>\n",
       "      <td>usa</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>front-wheel_drive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.688217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>3079.038997</td>\n",
       "      <td>15.1</td>\n",
       "      <td>2018</td>\n",
       "      <td>europe</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>front-wheel_drive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.246341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2542.392402</td>\n",
       "      <td>20.2</td>\n",
       "      <td>2009</td>\n",
       "      <td>usa</td>\n",
       "      <td>diesel</td>\n",
       "      <td>all-wheel_drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.912736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3460.870990</td>\n",
       "      <td>14.4</td>\n",
       "      <td>2009</td>\n",
       "      <td>europe</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>all-wheel_drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.488369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   engine_displacement  num_cylinders  horsepower  vehicle_weight  \\\n",
       "0                  170            3.0       159.0     3413.433759   \n",
       "1                  130            5.0        97.0     3149.664934   \n",
       "2                  170            NaN        78.0     3079.038997   \n",
       "3                  220            4.0         NaN     2542.392402   \n",
       "4                  210            1.0       140.0     3460.870990   \n",
       "\n",
       "   acceleration  model_year  origin fuel_type         drivetrain  num_doors  \\\n",
       "0          17.7        2003  europe  gasoline    all-wheel_drive        0.0   \n",
       "1          17.8        2007     usa  gasoline  front-wheel_drive        0.0   \n",
       "2          15.1        2018  europe  gasoline  front-wheel_drive        0.0   \n",
       "3          20.2        2009     usa    diesel    all-wheel_drive        2.0   \n",
       "4          14.4        2009  europe  gasoline    all-wheel_drive        2.0   \n",
       "\n",
       "   fuel_efficiency_mpg  \n",
       "0            13.231729  \n",
       "1            13.688217  \n",
       "2            14.246341  \n",
       "3            16.912736  \n",
       "4            12.488369  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbbaa400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the target variable before any splitting/filling\n",
    "y = df[target]\n",
    "df = df.drop(columns=[target])\n",
    "# Fill missing values\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e20dc289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Train/Validation/Test Split (60%/20%/20%)\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "# Separate target variables (y) for each set\n",
    "y_train = y.loc[df_train.index]\n",
    "y_val = y.loc[df_val.index]\n",
    "y_test = y.loc[df_test.index]\n",
    "\n",
    "# Reset indices for clean conversion to dicts\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_val = y_val.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# Convert DataFrames to Dicts (Required for DictVectorizer)\n",
    "train_dicts = df_train.to_dict(orient=\"records\")\n",
    "val_dicts = df_val.to_dict(orient=\"records\")\n",
    "test_dicts = df_test.to_dict(orient=\"records\")\n",
    "\n",
    "# Use DictVectorizer to turn dicts into feature matrices\n",
    "dv = DictVectorizer(sparse=True)\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "X_val = dv.transform(val_dicts)\n",
    "X_test = dv.transform(test_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fda8f2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    \"\"\"Calculates Root Mean Squared Error (RMSE)\"\"\"\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088c6d67",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Let's train a decision tree regressor to predict the `fuel_efficiency_mpg` variable. \n",
    "\n",
    "* Train a model with `max_depth=1`.\n",
    "\n",
    "\n",
    "Which feature is used for splitting the data?\n",
    "\n",
    "\n",
    "* `'vehicle_weight'`\n",
    "* `'model_year'`\n",
    "* `'origin'`\n",
    "* `'fuel_type'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "637db725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 - Feature used for splitting (max_depth=1): vehicle_weight\n"
     ]
    }
   ],
   "source": [
    "# Train a Decision Tree Regressor with max_depth=1\n",
    "dt = DecisionTreeRegressor(max_depth=1, random_state=1)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Get the feature importance\n",
    "feature_importances = pd.Series(\n",
    "    dt.feature_importances_, index=dv.get_feature_names_out()\n",
    ")\n",
    "most_important_feature = feature_importances.idxmax()\n",
    "split_value = feature_importances.max()\n",
    "\n",
    "print(f\"Q1 - Feature used for splitting (max_depth=1): {most_important_feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c3ca31",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Train a random forest regressor with these parameters:\n",
    "\n",
    "* `n_estimators=10`\n",
    "* `random_state=1`\n",
    "* `n_jobs=-1` (optional - to make training faster)\n",
    "\n",
    "\n",
    "What's the RMSE of this model on the validation data?\n",
    "\n",
    "* 0.045\n",
    "* 0.45\n",
    "* 4.5\n",
    "* 45.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3da4013e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2 - RMSE on validation data (n_estimators=10): 0.460\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Regressor with n_estimators=10\n",
    "rf = RandomForestRegressor(n_estimators=10, random_state=1, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation data\n",
    "y_pred_val = rf.predict(X_val)\n",
    "\n",
    "# Calculate RMSE on validation data\n",
    "rmse_val_q2 = rmse(y_val, y_pred_val)\n",
    "\n",
    "print(f\"Q2 - RMSE on validation data (n_estimators=10): {rmse_val_q2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f15319",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Now let's experiment with the `n_estimators` parameter\n",
    "\n",
    "* Try different values of this parameter from 10 to 200 with step 10.\n",
    "* Set `random_state` to `1`.\n",
    "* Evaluate the model on the validation dataset.\n",
    "\n",
    "\n",
    "After which value of `n_estimators` does RMSE stop improving?\n",
    "Consider 3 decimal places for calculating the answer.\n",
    "\n",
    "- 10\n",
    "- 25\n",
    "- 80\n",
    "- 200\n",
    "\n",
    "If it doesn't stop improving, use the latest iteration number in\n",
    "your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83b64fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3 - n_estimators vs RMSE:\n",
      " n_estimators     rmse\n",
      "           10 0.459578\n",
      "           20 0.453591\n",
      "           30 0.451687\n",
      "           40 0.448721\n",
      "           50 0.446657\n",
      "           60 0.445460\n",
      "           70 0.445126\n",
      "           80 0.444984\n",
      "           90 0.444861\n",
      "          100 0.444652\n",
      "          110 0.443579\n",
      "          120 0.443912\n",
      "          130 0.443703\n",
      "          140 0.443355\n",
      "          150 0.442898\n",
      "          160 0.442761\n",
      "          170 0.442801\n",
      "          180 0.442362\n",
      "          190 0.442494\n",
      "          200 0.442479\n",
      "\n",
      "Q3 - RMSE stops improving after n_estimators=70.0\n"
     ]
    }
   ],
   "source": [
    "# Experiment with n_estimators from 10 to 200 with step 10\n",
    "scores = []\n",
    "n_estimators_list = range(10, 201, 10)\n",
    "\n",
    "for n in n_estimators_list:\n",
    "    rf = RandomForestRegressor(n_estimators=n, random_state=1, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_val = rf.predict(X_val)\n",
    "    rmse_val = rmse(y_val, y_pred_val)\n",
    "\n",
    "    scores.append((n, rmse_val))\n",
    "\n",
    "df_scores_q3 = pd.DataFrame(scores, columns=[\"n_estimators\", \"rmse\"])\n",
    "\n",
    "# Find when RMSE stops improving (consider 3 decimal places)\n",
    "# We look for the point where the difference between two consecutive RMSEs is very small (e.g., < 0.001) or starts increasing.\n",
    "best_n = df_scores_q3.iloc[0][\"n_estimators\"]\n",
    "min_rmse = df_scores_q3.iloc[0][\"rmse\"]\n",
    "\n",
    "print(\"Q3 - n_estimators vs RMSE:\")\n",
    "print(df_scores_q3.to_string(index=False))\n",
    "\n",
    "# Check when the improvement is marginal (e.g., less than 0.001)\n",
    "improvement_threshold = 0.001\n",
    "n_stop_improving = None\n",
    "\n",
    "for i in range(1, len(df_scores_q3)):\n",
    "    prev_rmse = df_scores_q3.iloc[i - 1][\"rmse\"]\n",
    "    current_rmse = df_scores_q3.iloc[i][\"rmse\"]\n",
    "\n",
    "    if (prev_rmse - current_rmse) < improvement_threshold:\n",
    "        n_stop_improving = df_scores_q3.iloc[i][\"n_estimators\"]\n",
    "        break\n",
    "\n",
    "print(f\"\\nQ3 - RMSE stops improving after n_estimators={n_stop_improving}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b981ed",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Let's select the best `max_depth`:\n",
    "\n",
    "* Try different values of `max_depth`: `[10, 15, 20, 25]`\n",
    "* For each of these values,\n",
    "  * try different values of `n_estimators` from 10 till 200 (with step 10)\n",
    "  * calculate the mean RMSE \n",
    "* Fix the random seed: `random_state=1`\n",
    "\n",
    "\n",
    "What's the best `max_depth`, using the mean RMSE?\n",
    "\n",
    "* 10\n",
    "* 15\n",
    "* 20\n",
    "* 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6b8baaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4 - max_depth vs Mean RMSE:\n",
      " max_depth  mean_rmse\n",
      "        10   0.441808\n",
      "        15   0.445417\n",
      "        20   0.446253\n",
      "        25   0.445910\n",
      "\n",
      "Q4 - Best max_depth based on mean RMSE: 10.0 (Mean RMSE: 0.4418)\n"
     ]
    }
   ],
   "source": [
    "# Select the best max_depth\n",
    "max_depths = [10, 15, 20, 25]\n",
    "n_estimators_list = range(10, 201, 10)\n",
    "scores_q4 = []\n",
    "\n",
    "for depth in max_depths:\n",
    "    rmse_per_depth = []\n",
    "    for n in n_estimators_list:\n",
    "        rf = RandomForestRegressor(\n",
    "            n_estimators=n, max_depth=depth, random_state=1, n_jobs=-1\n",
    "        )\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_val = rf.predict(X_val)\n",
    "        rmse_val = rmse(y_val, y_pred_val)\n",
    "        rmse_per_depth.append(rmse_val)\n",
    "\n",
    "    # Calculate mean RMSE for the current max_depth\n",
    "    mean_rmse = np.mean(rmse_per_depth)\n",
    "    scores_q4.append((depth, mean_rmse))\n",
    "\n",
    "df_scores_q4 = pd.DataFrame(scores_q4, columns=[\"max_depth\", \"mean_rmse\"])\n",
    "best_max_depth = df_scores_q4.loc[df_scores_q4[\"mean_rmse\"].idxmin()]\n",
    "\n",
    "print(\"Q4 - max_depth vs Mean RMSE:\")\n",
    "print(df_scores_q4.to_string(index=False))\n",
    "\n",
    "print(\n",
    "    f\"\\nQ4 - Best max_depth based on mean RMSE: {best_max_depth['max_depth']} (Mean RMSE: {best_max_depth['mean_rmse']:.4f})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b66149c",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "We can extract feature importance information from tree-based models. \n",
    "\n",
    "At each step of the decision tree learning algorithm, it finds the best split. \n",
    "When doing it, we can calculate \"gain\" - the reduction in impurity before and after the split. \n",
    "This gain is quite useful in understanding what are the important features for tree-based models.\n",
    "\n",
    "In Scikit-Learn, tree-based models contain this information in the\n",
    "[`feature_importances_`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor.feature_importances_)\n",
    "field. \n",
    "\n",
    "For this homework question, we'll find the most important feature:\n",
    "\n",
    "* Train the model with these parameters:\n",
    "  * `n_estimators=10`,\n",
    "  * `max_depth=20`,\n",
    "  * `random_state=1`,\n",
    "  * `n_jobs=-1` (optional)\n",
    "* Get the feature importance information from this model\n",
    "\n",
    "\n",
    "What's the most important feature (among these 4)? \n",
    "\n",
    "* `vehicle_weight`\n",
    "*\t`horsepower`\n",
    "* `acceleration`\n",
    "* `engine_displacement`\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e7a0656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5 - Feature importances (filtered):\n",
      "vehicle_weight         0.959150\n",
      "horsepower             0.015998\n",
      "acceleration           0.011480\n",
      "engine_displacement    0.003273\n",
      "dtype: float64\n",
      "\n",
      "Q5 - Most important feature: vehicle_weight\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest Regressor to get feature importance\n",
    "rf_q5 = RandomForestRegressor(n_estimators=10, max_depth=20, random_state=1, n_jobs=-1)\n",
    "rf_q5.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance\n",
    "feature_importances_q5 = pd.Series(\n",
    "    rf_q5.feature_importances_, index=dv.get_feature_names_out()\n",
    ")\n",
    "\n",
    "# Filter for the 4 features in question\n",
    "target_features = [\n",
    "    \"vehicle_weight\",\n",
    "    \"horsepower\",\n",
    "    \"acceleration\",\n",
    "    \"engine_displacement\",\n",
    "]\n",
    "filtered_importance = feature_importances_q5[target_features]\n",
    "most_important_feature_q5 = filtered_importance.idxmax()\n",
    "\n",
    "print(\n",
    "    f\"Q5 - Feature importances (filtered):\\n{filtered_importance.sort_values(ascending=False)}\"\n",
    ")\n",
    "print(f\"\\nQ5 - Most important feature: {most_important_feature_q5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225d0cd3",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Now let's train an XGBoost model! For this question, we'll tune the `eta` parameter:\n",
    "\n",
    "* Install XGBoost\n",
    "* Create DMatrix for train and validation\n",
    "* Create a watchlist\n",
    "* Train a model with these parameters for 100 rounds:\n",
    "\n",
    "```\n",
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "```\n",
    "\n",
    "Now change `eta` from `0.3` to `0.1`.\n",
    "\n",
    "Which eta leads to the best RMSE score on the validation dataset?\n",
    "\n",
    "* 0.3\n",
    "* 0.1\n",
    "* Both give equal value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80857ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\001_Weiterbildung\\01_Programming\\Zoomcamp\\machine-learning-zoomcamp\\.venv\\Lib\\site-packages\\xgboost\\core.py:771: FutureWarning: Pass `evals` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "d:\\001_Weiterbildung\\01_Programming\\Zoomcamp\\machine-learning-zoomcamp\\.venv\\Lib\\site-packages\\xgboost\\core.py:771: FutureWarning: Pass `evals` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q6 - RMSE (eta=0.3): 0.4502\n",
      "Q6 - RMSE (eta=0.1): 0.4262\n",
      "\n",
      "Q6 - The best eta is: 0.1\n"
     ]
    }
   ],
   "source": [
    "# 1. Create DMatrix for train and validation\n",
    "# FIX: Get feature names and convert them to a Python list\n",
    "feature_names = dv.get_feature_names_out().tolist()\n",
    "\n",
    "# Use the 'feature_names' list when creating DMatrix\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=feature_names)\n",
    "dval = xgb.DMatrix(X_val, label=y_val, feature_names=feature_names)\n",
    "\n",
    "# 2. Define watchlist\n",
    "watchlist = [(dtrain, \"train\"), (dval, \"val\")]\n",
    "\n",
    "xgb_params = {\n",
    "    \"max_depth\": 6,\n",
    "    \"min_child_weight\": 1,\n",
    "    \"objective\": \"reg:squarederror\",  # Regression objective\n",
    "    \"nthread\": 8,\n",
    "    \"seed\": 1,\n",
    "    \"verbosity\": 0,  # Set to 0 to suppress excessive output during training\n",
    "}\n",
    "num_round = 100\n",
    "\n",
    "\n",
    "# Function to train and evaluate XGBoost\n",
    "def train_and_eval_xgb(eta_value, xgb_params, num_round, watchlist):\n",
    "    params = xgb_params.copy()\n",
    "    params[\"eta\"] = eta_value\n",
    "\n",
    "    # Train the model\n",
    "    model = xgb.train(\n",
    "        params, dtrain, num_round, watchlist, evals_result={}, verbose_eval=False\n",
    "    )\n",
    "\n",
    "    # Predict on validation set\n",
    "    y_pred_val_xgb = model.predict(dval)\n",
    "    # Calculate RMSE\n",
    "    rmse_val_xgb = rmse(y_val, y_pred_val_xgb)\n",
    "\n",
    "    return rmse_val_xgb\n",
    "\n",
    "\n",
    "# Case 1: eta = 0.3\n",
    "rmse_03 = train_and_eval_xgb(0.3, xgb_params, num_round, watchlist)\n",
    "\n",
    "# Case 2: eta = 0.1\n",
    "rmse_01 = train_and_eval_xgb(0.1, xgb_params, num_round, watchlist)\n",
    "\n",
    "print(f\"Q6 - RMSE (eta=0.3): {rmse_03:.4f}\")\n",
    "print(f\"Q6 - RMSE (eta=0.1): {rmse_01:.4f}\")\n",
    "\n",
    "# Determine the best eta\n",
    "if rmse_03 < rmse_01:\n",
    "    best_eta = 0.3\n",
    "elif rmse_01 < rmse_03:\n",
    "    best_eta = 0.1\n",
    "else:\n",
    "    best_eta = \"Both equal\"\n",
    "\n",
    "print(f\"\\nQ6 - The best eta is: {best_eta}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-zoomcamp-homework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
